---
title: "p8105_hw3_js5431"
author: "J Shearston"
date: "October 6, 2018"
output: 
  github_document:
    toc: true
---

```{r setup, include=FALSE}
library(tidyverse)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_bw() + theme(legend.position = "bottom"))

```


## Problem #1

#### Data Import and Cleaning

```{r load & clean BRFSS}

library(p8105.datasets)

brfss = p8105.datasets::brfss_smart2010 %>% 
  janitor::clean_names() %>%
  rename(state = locationabbr, 
         county = locationdesc) %>% 
  filter(topic == "Overall Health") %>%
  arrange(year, state, county) %>% 
  mutate(response = ordered(response, levels = c("Excellent", "Very good", "Good", "Fair", "Poor"))) %>%
  select(year, state, county, response, data_value)


```


#### Questions and Responses

* In 2002, which states were observed at 7 locations?
    + In 2002, 3 states were observed at 7 locations: Connecticut, Florida, and North Carolina.
    
```{r states observed at 7 loc.}

 brfss %>% 
  filter(year == "2002") %>% 
  group_by(state) %>% 
  summarize(n_counties = n_distinct(county)) %>% 
  filter(n_counties == 7)

```
    

* Make a “spaghetti plot” that shows the number of locations in each state from 2002 to 2010.
    + This plot is horrifying. I removed the legend, as trying to determine which line represents which individual state is anxiety inducing. Overall, I would say that this plot shows that for most states, the total number of locations has remained fairly constant over time, with a few states having very large variability.

```{r spaghetti plot - obs by state}

brfss %>%
  group_by(year, state) %>% 
  summarize(n_counties = n_distinct(county)) %>% 
  ggplot(aes(x = year, y = n_counties, color = state)) +
  geom_line() +
  labs(
    title = "Total Observations",
    x = "Year",
    y = "No. of Observed Counties",
    caption = "Data from the BRFSS, p8105 datasets package") +
  theme(legend.position="none")
  
```


* Make a table showing, for the years 2002, 2006, and 2010, the mean and standard deviation of the proportion of “Excellent” responses across locations in NY State.
    + The mean and standard deviation of the proportion of "Excellent" responses is pretty similar for NY state for all three years. 

```{r table}

brfss %>% 
  filter(state == "NY", 
         response == "Excellent", 
         year == 2002 | year == 2006 | year ==2010) %>% 
  group_by(year) %>% 
  summarize(excel_mean = mean(data_value),
            excel_sd = sd(data_value)) %>% 
  knitr::kable(digits = 2)

```


* For each year and state, compute the average proportion in each response category (taking the average across locations in a state). Make a five-panel plot that shows, for each response category separately, the distribution of these state-level averages over time.
    + Over time, the proportion of overall responses in each category seems to stay fairly consistent, such that "Very good" is consistently the most selected response, and "Poor" is the least selected. Within each category, there is some variability by state in the actual proportion of respondents who select each choice; interestingly, this variability sees similar for each choice, with the exception of "Poor", which seems to have a smaller variability.

```{r 5 panel plot}

brfss %>%
  group_by(year, state, response) %>% 
  summarise(avgby_response = mean(data_value, na.rm = (TRUE), round(2))) %>%
  ggplot(aes(x = year, y = avgby_response, color = state)) +
  geom_point() +
  facet_grid(~response) +
  theme(legend.position = "none")

```


## Problem #2

#### Data import and cleaning

```{r load and clean Instacart}

library(p8105.datasets)

icart = p8105.datasets::instacart %>% 
  janitor::clean_names()

```

#### Instacart dataset description

The Instacart dataset includes data from selected orders from an online grocery store; it contains `r nrow(icart)` rows and `r ncol(icart)` columns, and is formatted such that each row is a product from an order. Only one order for any particular individual is inlcuded.

Key variables include several unique IDs, such as order ID, product ID, and user ID; product information such as product name, aisle, and department; and interesting order information such as the time of day the order was placed and if the item has been ordered before. For example, an individual (user id = 112108) purchased 8 items as part of their order, including yogurt, milk, celery, cucumber, sardines, bananas, avacado, and string cheese. These items were ordered at 10 am, and 4 of them had been ordered by this customer in the past. 

#### Questions and responses

* How many aisles are there, and which aisles are the most items ordered from?
    + There are 134 aisles, and the following aisles are most ordered from: Fresh vegetables, fresh fruits, packaged vegetables fruits, yogurt, and packaged cheese. 
    
```{r}

icart %>%
  summarize(dist_aisle = n_distinct(aisle_id, na.rm = TRUE))

icart %>% 
  group_by(aisle) %>% 
  summarize(n()) %>% 
  top_n(5)


```


* Make a plot that shows the number of items ordered in each aisle. Order aisles sensibly, and organize your plot so others can read it.

```{r}

icart %>% 
  group_by(department, aisle) %>% 
  summarize(items_aisle = n()) %>% 
  ggplot(aes(x = department, y = aisle)) +
  geom_point(aes(size = items_aisle), alpha = .5) 

```


* Make a table showing the most popular item aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”

* Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).
